<!DOCTYPE html>
<html lang="id">
<head>
  <meta charset="UTF-8">
  <title>Deteksi Wajah Real-Time</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
  <style>
    body {
      margin: 0;
      font-family: sans-serif;
      background: #000;
      color: #fff;
      text-align: center;
    }
    video, canvas {
      margin-top: 20px;
      border: 2px solid #fff;
    }
    button {
      margin: 10px;
      padding: 10px 20px;
      font-size: 16px;
      cursor: pointer;
    }
  </style>
</head>
<body>

  <h1>Deteksi Wajah Real-Time</h1>
  <video id="webcam" width="640" height="480" autoplay muted playsinline></video>
  <canvas id="overlay" width="640" height="480"></canvas><br>

  <button id="startBtn">Start Kamera</button>
  <button id="stopBtn" disabled>Stop Kamera</button>
  <button id="detectBtn" disabled>Aktifkan Deteksi Wajah</button>

  <script>
    let model, webcamStream, animationId;
    let detectionOn = false;
    let lastCaptureTime = 0;
    const captureInterval = 5000; // 5 detik

    const video = document.getElementById('webcam');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d');

    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const detectBtn = document.getElementById('detectBtn');

    async function setupCamera() {
      webcamStream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = webcamStream;
      return new Promise(resolve => {
        video.onloadedmetadata = () => resolve(video);
      });
    }

    async function detectFaces() {
      const predictions = await model.estimateFaces(video, false);

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      if (detectionOn && predictions.length > 0) {
        const now = Date.now();
        if (now - lastCaptureTime > captureInterval) {
          lastCaptureTime = now;
          takeSnapshot();
        }

        predictions.forEach(pred => {
          const [x, y] = pred.topLeft;
          const [x2, y2] = pred.bottomRight;
          const width = x2 - x;
          const height = y2 - y;

          ctx.strokeStyle = "lime";
          ctx.lineWidth = 3;
          ctx.strokeRect(x, y, width, height);
        });
      }

      animationId = requestAnimationFrame(detectFaces);
    }

    function takeSnapshot() {
      const snapshotCanvas = document.createElement('canvas');
      snapshotCanvas.width = canvas.width;
      snapshotCanvas.height = canvas.height;
      const snapshotCtx = snapshotCanvas.getContext('2d');
      snapshotCtx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const imageData = snapshotCanvas.toDataURL('image/png');

      const link = document.createElement('a');
      link.href = imageData;
      link.download = `wajah_terdeteksi_${Date.now()}.png`;
      link.click();
    }

    async function startApp() {
      startBtn.disabled = true;
      stopBtn.disabled = false;
      detectBtn.disabled = false;

      model = await blazeface.load();
      await setupCamera();
      video.play();
      detectFaces();
    }

    function stopApp() {
      startBtn.disabled = false;
      stopBtn.disabled = true;
      detectBtn.disabled = true;
      detectionOn = false;

      if (webcamStream) {
        webcamStream.getTracks().forEach(track => track.stop());
      }

      cancelAnimationFrame(animationId);
      ctx.clearRect(0, 0, canvas.width, canvas.height);
    }

    startBtn.onclick = startApp;
    stopBtn.onclick = stopApp;
    detectBtn.onclick = () => {
      detectionOn = !detectionOn;
      detectBtn.textContent = detectionOn ? 'Matikan Deteksi Wajah' : 'Aktifkan Deteksi Wajah';
    };
  </script>

</body>
</html>
